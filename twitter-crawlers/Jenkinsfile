def label = "worker-${UUID.randomUUID().toString()}"

properties([
  buildDiscarder(logRotator(numToKeepStr: '50')),
  disableConcurrentBuilds(),
  parameters([
    string(defaultValue: '172.16.221.85:9200', description: 'Elasticsearch URL', name: 'ES_URL', trim: true),
    string(defaultValue: 'twitter', description: 'Elasticsearch Index', name: 'ES_INDEX', trim: true),
    string(defaultValue: 'tweet', description: 'Elasticsearch Type', name: 'ES_TYPE', trim: true),
    string(defaultValue: '''DarkReading,kaspersky,paulsparrows,demonslay335,haveibeenpwned''',
      description: 'Twitter Accounts', name: 'TWITTER_ACCOUNTS', trim: true)]),
  pipelineTriggers([cron('H(0-10) * * * *')])
])

node {
  stage("Pull docker image") {
    sh """docker pull enisa2018/twitter-crawlers:latest"""
  }
  stage("Scrape [Twitter]") {
    sh """
    docker run -i --rm \
    -e "ES_URL=${params.ES_URL}" \
    -e "ES_INDEX=${params.ES_INDEX}" \
    -e "ES_TYPE=${params.ES_TYPE}" \
    -e "TW_CONSUMER_KEY=${env.TW_CONSUMER_KEY}" \
    -e "TW_CONSUMER_SECRET=${env.TW_CONSUMER_SECRET}" \
    -e "TW_ACCESS_TOKEN_KEY=${env.TW_ACCESS_TOKEN_KEY}" \
    -e "TW_ACCESS_TOKEN_SECRET=${env.TW_ACCESS_TOKEN_SECRET}" \
    -e "TW_LIMIT=30" \
    -e "TW_IDS=${params.TWITTER_ACCOUNTS}" \
    enisa2018/twitter-crawlers:latest
    """
  }
}
