properties([
  buildDiscarder(logRotator(numToKeepStr: '50')),
  disableConcurrentBuilds(),
  parameters([
    string(defaultValue: '172.16.221.85:9200', description: 'Elasticsearch URL', name: 'ES_URL', trim: true),
    string(defaultValue: 'twitter', description: 'Elasticsearch Index', name: 'ES_INDEX', trim: true),
    string(defaultValue: 'tweet', description: 'Elasticsearch Type', name: 'ES_TYPE', trim: true),
    string(defaultValue: '''DarkReading,kaspersky,paulsparrows,demonslay335,haveibeenpwned''',
      description: 'Twitter Accounts', name: 'TWITTER_ACCOUNTS', trim: true)]),
  pipelineTriggers([cron('H(0-10) * * * *')])
])

node {
  checkout scm

  stage('Build docker image') {
    dir ('twitter-crawlers') {
      sh """docker build -t twitter-crawlers ."""
    }
  }

  stage("Scrape [Twitter]") {
    dir('twitter-crawlers') {
      sh """
      docker run -i --rm \
      -e "ES_URL=${params.ES_URL}" \
      -e "ES_INDEX=${params.ES_INDEX}" \
      -e "ES_TYPE=${params.ES_TYPE}" \
      -e "TW_CONSUMER_KEY=${env.TW_CONSUMER_KEY}" \
      -e "TW_CONSUMER_SECRET=${env.TW_CONSUMER_SECRET}" \
      -e "TW_ACCESS_TOKEN_KEY=${env.TW_ACCESS_TOKEN_KEY}" \
      -e "TW_ACCESS_TOKEN_SECRET=${env.TW_ACCESS_TOKEN_SECRET}" \
      -e "TW_LIMIT=30" \
      -e "TW_IDS=${params.TWITTER_ACCOUNTS}" \
      twitter-crawlers
      """
    }
  }
}
